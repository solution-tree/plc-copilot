---
validationTarget: 'apps/api/docs/prd-v4.md'
validationDate: '2026-02-26'
inputDocuments:
  - apps/api/docs/prd-v4.md
  - apps/api/docs/research/ferpa-FINAL.md
validationStepsCompleted: [step-v-01-discovery]
validationStatus: IN_PROGRESS
---

# PRD Validation Report

**PRD Being Validated:** apps/api/docs/prd-v4.md
**Validation Date:** 2026-02-26

## Input Documents

- **PRD:** PRD: PLC Coach Service (MVP) v4.1 — `apps/api/docs/prd-v4.md`
- **FERPA Compliance Report:** FERPA Compliance Report for PLC Coach Platform — `apps/api/docs/research/ferpa-FINAL.md`

## Validation Findings

### Pre-Validation: Self-Consistency Analysis (Advanced Elicitation)

A self-consistency validation was run across all PRD sections before the formal validation steps began. The following findings were identified by the BMAD agent team.

#### Finding 1 — Corpus Size Mismatch (PRD vs. FERPA Research) ❌

- **PRD** consistently references **25 books** (Sections 3.1, 6, 8, 9)
- **FERPA Research** (`ferpa-FINAL.md`) references **22 books** in multiple places (Sections 5, 7)
- **Impact:** Downstream artifacts could plan for the wrong corpus size
- **Recommendation:** Reconcile the correct number and update both documents

#### Finding 2 — "What, Not How" Boundary Violated ❌

- PRD opening states implementation details belong in the Technical Specification
- PRD then includes: specific tool names (PyMuPDF, llmsherpa, GPT-4o Vision), model IDs (`cross-encoder/ms-marco-MiniLM-L-6-v2`, `text-embedding-3-large`), full database schemas with column types, AWS instance sizes (`t4g.medium`, `cache.t3.micro`), and BM25 implementation strategy
- **Impact:** Blurs the line between PRD and Tech Spec; creates dual maintenance burden
- **Recommendation:** Either remove the scope disclaimer or move implementation details to the Tech Spec

#### Finding 3 — AC #1 Cross-Reference Error ❌

- AC #1 says: "All Zone A infrastructure described in **Section 6**..."
- The Three-Zone Tenant Enclave Model is defined in **Section 7**, not Section 6
- **Impact:** Broken cross-reference could confuse implementation teams
- **Recommendation:** Update AC #1 to reference Section 7

#### Finding 4 — "No Performance Optimization" vs. Performance-Motivated Decisions ⚠️

- Section 2.2 lists "No Performance Optimization" as a non-goal
- Decision #5 rejects PostgreSQL `ts_rank` due to scaling/performance bottleneck concerns
- Decision #6 references simplified architecture implying scaling was considered
- Re-ranking pipeline (Section 3.3) is itself a performance optimization pattern
- **Impact:** Sends mixed signals about whether performance matters for MVP
- **Recommendation:** Clarify that the non-goal refers to response-time tuning, not architectural quality-of-retrieval decisions — or reword the non-goal

#### Finding 5 — Evaluation Phase vs. AC Threshold Ambiguity ⚠️

- Phase 0-B (during build) only measures Faithfulness and Answer Relevancy (reference-free)
- Phase 3 (final) adds Context Precision and Context Recall (requires expert-authored answers)
- AC #11 requires all four thresholds, implicitly requiring Phase 3 completion
- **Impact:** MVP completion is blocked on obtaining expert-authored answers for 50-100 questions — a dependency not explicitly called out
- **Recommendation:** Explicitly state that Phase 3 expert answers are a prerequisite for MVP sign-off, or split the AC into phased thresholds

#### Finding 6 — Observability vs. Audit Logging Disconnect ⚠️

- Section 6.1: "Observability is limited to basic CloudWatch log groups"
- Section 7.2: "Structured JSON logs capture key events with metadata"
- Relationship between these two statements is not explicit
- **Impact:** Unclear whether audit logs are CloudWatch logs or a separate mechanism — matters for future FERPA compliance
- **Recommendation:** Consolidate logging/observability into one section or cross-reference explicitly

#### Finding 7 — `conversation_id` Type Inconsistency ⚠️

- Section 5.2 describes `conversation_id` as "UUID generated by the client"
- Same section says "the server does not validate it as a UUID — it is accepted as a plain string"
- Decision #9 calls it the "foundation for Phase 2 memory"
- **Impact:** Accepting arbitrary strings now creates data quality debt for the Phase 2 memory foundation
- **Recommendation:** Acknowledge this as a deliberate trade-off or add lightweight validation

#### Consistency Scorecard

| Trace Path | Status | Notes |
|---|---|---|
| Vision → Goals | ✅ Aligned | Goals clearly serve the vision |
| Goals → Features | ✅ Aligned | Features map to all three goals |
| Features → API Spec | ✅ Aligned | All query types covered in flows |
| Features → Data Models | ✅ Aligned | Schema supports all features |
| Goals → Acceptance Criteria | ⚠️ Partial | AC #11 has implicit Phase 3 dependency |
| PRD Scope Statement → Actual Content | ❌ Misaligned | Extensive implementation details despite disclaimer |
| PRD → FERPA Research | ❌ Misaligned | 25 books vs. 22 books |
| AC Cross-References | ❌ Broken | AC #1 points to Section 6, should be Section 7 |
| Non-Goals → Decisions | ⚠️ Tension | "No perf optimization" vs. perf-motivated decisions |
| Security → Observability | ⚠️ Unclear | Audit logging and observability described separately |
